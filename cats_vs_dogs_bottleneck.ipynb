{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras\n",
    "\n",
    "#### Alec Chapman\n",
    "\n",
    "This tutorial was adapted from [this keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "\n",
    "\n",
    "The data comes from a [Kaggle competition to classify images as being cats or dogs. The data can be downloaded [here](https://www.kaggle.com/c/dogs-vs-cats/data) after signing into Kaggle (either via a Kaggle account or Google, Facebook, or Yahoo!).\n",
    "\n",
    "## What is Keras?\n",
    "\n",
    "Keras is a high-level deep learning API written in Python. Keras uses [TensorFlow](https://www.tensorflow.org/) (Google), [CNTK](https://github.com/Microsoft/cntk) (Microsoft), or [Theano](http://deeplearning.net/software/theano/) (University of Montreal) as a backend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some modules needed for our tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Paths to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = '/home/jovyan/DATA/keras_cat_dog/data'\n",
    "TRAINDIR = os.path.join(DATADIR, 'train')\n",
    "VALDIR = os.path.join(DATADIR, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "\n",
    "train_data_dir = TRAINDIR\n",
    "validation_data_dir = VALDIR\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Modifying Pre-trained Model\n",
    "\n",
    "```Python\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "```\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "```Python\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "```\n",
    "[ImageDataGenerator](https://keras.io/preprocessing/image/)\n",
    "Keras comes with various pre-defined models. The first time we instantiate a model, the weights are downloaded.\n",
    "\n",
    "```Python\n",
    "    weights='imagenet'\n",
    "```\n",
    "\n",
    "This will download the weights for the model trained on the imagenet data set. If `weights=None`, the weights will be assigned randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples / batch_size)\n",
    "    with open('bottleneck_features_train.npy', 'wb') as fp:\n",
    "        np.save(fp,\n",
    "                bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples / batch_size)\n",
    "    with open('bottleneck_features_validation.npy', 'wb') as fp:\n",
    "        np.save(fp,\n",
    "                bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    with open('bottleneck_features_train.npy', 'rb') as fp:\n",
    "        train_data = np.load(fp)\n",
    "    train_labels = np.array(\n",
    "        [0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
    "\n",
    "    # NOT SURE WHY I'M NOT ENDING UP WITH THE CORRECT NUMBER OF VALIDATIOAN_DATA POINTS\n",
    "    with open('bottleneck_features_validation.npy', 'rb') as fp:\n",
    "        validation_data = np.load(fp)\n",
    "    validation_labels = np.array(\n",
    "        [0] * int(len(validation_data) / 2) + [1] * int(len(validation_data) / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that I'm using the TensorFlow Backend\n",
    "\n",
    "This is controlled by an environment variable and is set in\n",
    "```bash\n",
    "/home/user/.keras/keras.json\n",
    "```\n",
    "which for me has the following content:\n",
    "\n",
    "```json\n",
    "\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = '/srv/DATA/keras_cat_dog/data'\n",
    "TRAINDIR = os.path.join(DATADIR, 'train')\n",
    "VALDIR = os.path.join(DATADIR, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this tutorial we'll build a Convolutional Neural Network to solve the age-old problem: Is it a **dog**, or a **cat**? \n",
    "\n",
    "Here's what we'll do today:\n",
    "- First, we'll look at what it actually means to deal with images in machine learning. \n",
    "- Then we'll starting using Keras, a great library that providers a higher-level API to sit on top of TensorFlow. \n",
    "- Finally, we'll train our model (for a bit) and then use a pre-trained model to classify a batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Images in Python\n",
    "\n",
    "Convolutional neural networks (CNNs) are often associated with computer vision. They're great at detecting edges, shapes, and higher-level features in images and using those findings to make a decision, such as classifying between cats and dogs. But how do we actually get these images into the neural net?\n",
    "\n",
    "Basically, images can be seen as arrays of pixels. If we flatten them, it would be one long array of numbers, where each array corresponds to a pixel. CNNs allow us to keep a grid-like shape rather than dealing with flat, 1-dimensional arrays. Specifically, our images will look like this:\n",
    "\n",
    "   ##### Height x Width x Channels \n",
    "where channels corresponds to the color channels (3 for RGB, 1 for grayscale). So a list of images being fed into a neural network will look like this:\n",
    "   ##### # of images x Height x Width x Channels\n",
    "   \n",
    "This array of matrices is often called a *tensor*.\n",
    "   \n",
    "Let's look at some examples.\n",
    "\n",
    "A great library for working with images in Python is the [Python Image Library](https://pillow.readthedocs.io/en/4.2.x/), or **PIL** (actually now **Pillow**, a fork of PIL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "example = os.path.join(TRAINDIR, 'cat', 'cat.1.jpg')\n",
    "img = Image.open(example)\n",
    "print(\"Width, height\")\n",
    "print(img.size)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great for a human. Now let's convert it to something the computer can understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(img)\n",
    "print(\"Height, width, Channels\")\n",
    "print(arr.shape)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And back...\n",
    "example = Image.fromarray(arr)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIL** offers great utility for working with images. Now let's look at Keras.\n",
    "\n",
    "### Keras \n",
    "[Keras](https://keras.io/) is an API that allows you to work with [TensorFlow](https://www.tensorflow.org/) or [Theano](http://deeplearning.net/software/theano/) in a much more user-friendly way. Per their description:\n",
    "\n",
    "```\n",
    "\"\"\"\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "\n",
    "- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "- Runs seamlessly on CPU and GPU.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "We'll get to neural nets in a minute. First let's look at some of the image functions Keras offers.\n",
    "\n",
    "##### Image Generators\n",
    "It's not always the case you have a bunch of data to train with. One solution to this is called **data augmentation**, where you create alterations of your existing data to provide more examples for your classifier. With images, that means that we'll stretch, augment, and crop the images so that we have a bunch of different versions of each of our images.\n",
    "\n",
    "Keras also offers a great utility called `flow_from_directory` that will allow us to put images in folders divided by class and Keras will automatically load them, know their label, and convert them into arrays to train/test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAINDIR,  # this is the target directory\n",
    "        target_size=(227, 227),  # all images will be resized to 227 x 227\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# No distorting for testing!\n",
    "# Instead, we'll rescale so that pixel values are between 0 and 1\n",
    "# Which, trust me, is very necessary.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALDIR,\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates 16 images from the images found in TRAINDIR. Let's look at a few of them\n",
    "print(x_batch.shape)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nimg = x_batch.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "for i in range(len(x_batch)):\n",
    "    x = x_batch[i]\n",
    "    print(x.shape)\n",
    "    print(y_batch)\n",
    "    ax = plt.subplot2grid((nimg//ncols+1, ncols), (i//ncols,i%ncols))\n",
    "    ax.imshow(x)\n",
    "    #img = array_to_img(x)\n",
    "    #img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of these get distorted. While this may look weird to us, it forces the classifier to look for other features that will allow it to recognize cats vs. dogs even with these strange distortions.\n",
    "\n",
    "Now, let's finally get to our trainer!\n",
    "\n",
    "### Convolutional Neural Networks\n",
    "As we covered a few weeks ago, CNNs are special because of what's called a Convolutional Layer. See our presentation for the details.\n",
    "\n",
    "Here is the architecture that we're going to use, based on Alexnet. It is probably too deep for the problem, and we'll have to look out for overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "print(\"Layer 1\")\n",
    "model.add(Conv2D(\n",
    "                filters=96,\n",
    "                kernel_size=11,\n",
    "                strides=4,\n",
    "                padding='valid',\n",
    "                input_shape= \\\n",
    "                    (227, 227, 3),\n",
    "                data_format='channels_last')\n",
    "          )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(\n",
    "                      pool_size=(3, 3),\n",
    "                      strides=(2,2),\n",
    "                      data_format='channels_last')\n",
    "         )\n",
    "\n",
    "print(\"Layer 2\")\n",
    "model.add(Conv2D(256, 5, strides=1, padding='valid', data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(\n",
    "          pool_size=(3, 3),\n",
    "          strides=(2,2),\n",
    "           data_format='channels_last')\n",
    "         )\n",
    "\n",
    "print(\"Layer 3\")\n",
    "model.add(Conv2D(\n",
    "           384, 3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           data_format='channels_last')\n",
    "         )\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "print(\"Segment 4\")\n",
    "model.add(Conv2D(\n",
    "                 256, 3,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format='channels_last')\n",
    "          )\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "print(\"Segment 5\")\n",
    "model.add(Conv2D(256, 3, strides=1, padding='valid', data_format='channels_last'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we're finally ready to train! Let's go.\n",
    "### But we don't want to since we are using CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000 // batch_size, # Number of batches\n",
    "    epochs=50, # Number of iterations. We're going to keep it small for now.\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=800//batch_size)\n",
    "```\n",
    "#model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(DATADIR, '..', 'cnn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /srv/DATA/keras_cat_dog/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(validation_generator, steps=500//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = random.choice(glob.glob(os.path.join(VALDIR, 'cat', 'cat*')))\n",
    "dog = random.choice(glob.glob(os.path.join(VALDIR, 'dog', 'dog*')))\n",
    "cat = Image.open(cat).resize((227, 227))\n",
    "dog = Image.open(dog).resize((227, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([img_to_array(img) for img in (cat, dog)]).reshape((2, 227, 227, 3))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALDIR,\n",
    "        target_size=(227, 227),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "x, y = next(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, accuracy\n",
    "model.evaluate_generator(validation_generator, steps = 500//16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
